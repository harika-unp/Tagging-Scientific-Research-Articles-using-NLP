{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTING LIBRARIES**\n"
      ],
      "metadata": {
        "id": "zGBfiQcPBkcl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfb89ZgfOotF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.formula.api as smf\n",
        "sns.set(color_codes=True)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import re,string\n",
        "%matplotlib inline\n",
        "from sklearn import model_selection, naive_bayes, svm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')\n",
        "import string\n",
        "string.punctuation\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLd_5D_KElu",
        "outputId": "a4a6232a-34cd-47c0-b478-edb58e417fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "zEl8kNHiBdR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/train.csv\",header = 0)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gpyzL40kRLho",
        "outputId": "19004b37-6f64-49aa-c844-1933b67c33da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   TITLE  \\\n",
              "0            Reconstructing Subject-Specific Effect Maps   \n",
              "1                     Rotation Invariance Neural Network   \n",
              "2      Spherical polyharmonics and Poisson kernels fo...   \n",
              "3      A finite element approximation for the stochas...   \n",
              "4      Comparative study of Discrete Wavelet Transfor...   \n",
              "...                                                  ...   \n",
              "20963  Contemporary machine learning: a guide for pra...   \n",
              "20964  Uniform diamond coatings on WC-Co hard alloy c...   \n",
              "20965  Analysing Soccer Games with Clustering and Con...   \n",
              "20966  On the Efficient Simulation of the Left-Tail o...   \n",
              "20967   Why optional stopping is a problem for Bayesians   \n",
              "\n",
              "                                                ABSTRACT  Computer Science  \\\n",
              "0        Predictive models allow subject-specific inf...                 1   \n",
              "1        Rotation invariance and translation invarian...                 1   \n",
              "2        We introduce and develop the notion of spher...                 0   \n",
              "3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "...                                                  ...               ...   \n",
              "20963    Machine learning is finding increasingly bro...                 1   \n",
              "20964    Polycrystalline diamond coatings have been g...                 0   \n",
              "20965    We present a new approach for identifying si...                 1   \n",
              "20966    The sum of Log-normal variates is encountere...                 0   \n",
              "20967    Recently, optional stopping has been a subje...                 0   \n",
              "\n",
              "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0            0            0           0                     0   \n",
              "1            0            0           0                     0   \n",
              "2            0            1           0                     0   \n",
              "3            0            1           0                     0   \n",
              "4            0            0           1                     0   \n",
              "...        ...          ...         ...                   ...   \n",
              "20963        1            0           0                     0   \n",
              "20964        1            0           0                     0   \n",
              "20965        0            0           0                     0   \n",
              "20966        0            1           1                     0   \n",
              "20967        0            1           1                     0   \n",
              "\n",
              "       Quantitative Finance  \n",
              "0                         0  \n",
              "1                         0  \n",
              "2                         0  \n",
              "3                         0  \n",
              "4                         0  \n",
              "...                     ...  \n",
              "20963                     0  \n",
              "20964                     0  \n",
              "20965                     0  \n",
              "20966                     0  \n",
              "20967                     0  \n",
              "\n",
              "[20968 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b854d58e-bc9c-4e45-a0f7-62ecad401d4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20963</th>\n",
              "      <td>Contemporary machine learning: a guide for pra...</td>\n",
              "      <td>Machine learning is finding increasingly bro...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20964</th>\n",
              "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
              "      <td>Polycrystalline diamond coatings have been g...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
              "      <td>We present a new approach for identifying si...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20966</th>\n",
              "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
              "      <td>The sum of Log-normal variates is encountere...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20967</th>\n",
              "      <td>Why optional stopping is a problem for Bayesians</td>\n",
              "      <td>Recently, optional stopping has been a subje...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20968 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b854d58e-bc9c-4e45-a0f7-62ecad401d4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b854d58e-bc9c-4e45-a0f7-62ecad401d4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b854d58e-bc9c-4e45-a0f7-62ecad401d4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtEKGuoFSB7r",
        "outputId": "a8814865-1107-4196-f53d-bbf4fccd64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TITLE                   0\n",
              "ABSTRACT                0\n",
              "Computer Science        0\n",
              "Physics                 0\n",
              "Mathematics             0\n",
              "Statistics              0\n",
              "Quantitative Biology    0\n",
              "Quantitative Finance    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(data.shape[1]):\n",
        "  print(data.iloc[:,i].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxe-DmfyS1JE",
        "outputId": "fcee4cf1-800a-4678-8a3e-97bebe2cff4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Reconstructing Subject-Specific Effect Maps'\n",
            " 'Rotation Invariance Neural Network'\n",
            " 'Spherical polyharmonics and Poisson kernels for polyharmonic functions'\n",
            " ... 'Analysing Soccer Games with Clustering and Conceptors'\n",
            " 'On the Efficient Simulation of the Left-Tail of the Sum of Correlated Log-normal Variates'\n",
            " 'Why optional stopping is a problem for Bayesians']\n",
            "[\"  Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n\"\n",
            " '  Rotation invariance and translation invariance have great values in image\\nrecognition tasks. In this paper, we bring a new architecture in convolutional\\nneural network (CNN) named cyclic convolutional layer to achieve rotation\\ninvariance in 2-D symbol recognition. We can also get the position and\\norientation of the 2-D symbol by the network to achieve detection purpose for\\nmultiple non-overlap target. Last but not least, this architecture can achieve\\none-shot learning in some cases using those invariance.\\n'\n",
            " '  We introduce and develop the notion of spherical polyharmonics, which are a\\nnatural generalisation of spherical harmonics. In particular we study the\\ntheory of zonal polyharmonics, which allows us, analogously to zonal harmonics,\\nto construct Poisson kernels for polyharmonic functions on the union of rotated\\nballs. We find the representation of Poisson kernels and zonal polyharmonics in\\nterms of the Gegenbauer polynomials. We show the connection between the\\nclassical Poisson kernel for harmonic functions on the ball, Poisson kernels\\nfor polyharmonic functions on the union of rotated balls, and the Cauchy-Hua\\nkernel for holomorphic functions on the Lie ball.\\n'\n",
            " ...\n",
            " '  We present a new approach for identifying situations and behaviours, which we\\ncall \"moves\", from soccer games in the 2D simulation league. Being able to\\nidentify key situations and behaviours are useful capabilities for analysing\\nsoccer matches, anticipating opponent behaviours to aid selection of\\nappropriate tactics, and also as a prerequisite for automatic learning of\\nbehaviours and policies. To support a wide set of strategies, our goal is to\\nidentify situations from data, in an unsupervised way without making use of\\npre-defined soccer specific concepts such as \"pass\" or \"dribble\". The recurrent\\nneural networks we use in our approach act as a high-dimensional projection of\\nthe recent history of a situation on the field. Similar situations, i.e., with\\nsimilar histories, are found by clustering of network states. The same networks\\nare also used to learn so-called conceptors, that are lower-dimensional\\nmanifolds that describe trajectories through a high-dimensional state space\\nthat enable situation-specific predictions from the same neural network. With\\nthe proposed approach, we can segment games into sequences of situations that\\nare learnt in an unsupervised way, and learn conceptors that are useful for the\\nprediction of the near future of the respective situation.\\n'\n",
            " '  The sum of Log-normal variates is encountered in many challenging\\napplications such as in performance analysis of wireless communication systems\\nand in financial engineering. Several approximation methods have been developed\\nin the literature, the accuracy of which is not ensured in the tail regions.\\nThese regions are of primordial interest wherein small probability values have\\nto be evaluated with high precision. Variance reduction techniques are known to\\nyield accurate, yet efficient, estimates of small probability values. Most of\\nthe existing approaches, however, have considered the problem of estimating the\\nright-tail of the sum of Log-normal random variables (RVS). In the present\\nwork, we consider instead the estimation of the left-tail of the sum of\\ncorrelated Log-normal variates with Gaussian copula under a mild assumption on\\nthe covariance matrix. We propose an estimator combining an existing\\nmean-shifting importance sampling approach with a control variate technique.\\nThe main result is that the proposed estimator has an asymptotically vanishing\\nrelative error which represents a major finding in the context of the left-tail\\nsimulation of the sum of Log-normal RVs. Finally, we assess by various\\nsimulation results the performances of the proposed estimator compared to\\nexisting estimators.\\n'\n",
            " \"  Recently, optional stopping has been a subject of debate in the Bayesian\\npsychology community. Rouder (2014) argues that optional stopping is no problem\\nfor Bayesians, and even recommends the use of optional stopping in practice, as\\ndo Wagenmakers et al. (2012). This article addresses the question whether\\noptional stopping is problematic for Bayesian methods, and specifies under\\nwhich circumstances and in which sense it is and is not. By slightly varying\\nand extending Rouder's (2014) experiment, we illustrate that, as soon as the\\nparameters of interest are equipped with default or pragmatic priors - which\\nmeans, in most practical applications of Bayes Factor hypothesis testing -\\nresilience to optional stopping can break down. We distinguish between four\\ntypes of default priors, each having their own specific issues with optional\\nstopping, ranging from no-problem-at-all (Type 0 priors) to quite severe (Type\\nII and III priors).\\n\"]\n",
            "[1 0]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(data.shape[1]):\n",
        "  print(data.iloc[:,i].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKkL7JNCS4Fd",
        "outputId": "2a36e063-1b93-44f2-e50e-d068857253c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing Subject-Specific Effect Maps                                                                                           1\n",
            "Can Deep Clinical Models Handle Real-World Domain Shifts?                                                                             1\n",
            "Memory Efficient Experience Replay for Streaming Learning                                                                             1\n",
            "Aspiration dynamics generate robust predictions in structured populations                                                             1\n",
            "OAuthGuard: Protecting User Security and Privacy with OAuth 2.0 and OpenID Connect                                                    1\n",
            "                                                                                                                                     ..\n",
            "The exit time finite state projection scheme: bounding exit distributions and occupation measures of continuous-time Markov chains    1\n",
            "The problem of boundary conditions for the shallow water equations (Russian)                                                          1\n",
            "A Deterministic Nonsmooth Frank Wolfe Algorithm with Coreset Guarantees                                                               1\n",
            "A Survey of Active Attacks on Wireless Sensor Networks and their Countermeasures                                                      1\n",
            "Why optional stopping is a problem for Bayesians                                                                                      1\n",
            "Name: TITLE, Length: 20968, dtype: int64\n",
            "  Predictive models allow subject-specific inference when analyzing disease\\nrelated alterations in neuroimaging data. Given a subject's data, inference can\\nbe made at two levels: global, i.e. identifiying condition presence for the\\nsubject, and local, i.e. detecting condition effect on each individual\\nmeasurement extracted from the subject's data. While global inference is widely\\nused, local inference, which can be used to form subject-specific effect maps,\\nis rarely used because existing models often yield noisy detections composed of\\ndispersed isolated islands. In this article, we propose a reconstruction\\nmethod, named RSM, to improve subject-specific detections of predictive\\nmodeling approaches and in particular, binary classifiers. RSM specifically\\naims to reduce noise due to sampling error associated with using a finite\\nsample of examples to train classifiers. The proposed method is a wrapper-type\\nalgorithm that can be used with different binary classifiers in a diagnostic\\nmanner, i.e. without information on condition presence. Reconstruction is posed\\nas a Maximum-A-Posteriori problem with a prior model whose parameters are\\nestimated from training data in a classifier-specific fashion. Experimental\\nevaluation is performed on synthetically generated data and data from the\\nAlzheimer's Disease Neuroimaging Initiative (ADNI) database. Results on\\nsynthetic data demonstrate that using RSM yields higher detection accuracy\\ncompared to using models directly or with bootstrap averaging. Analyses on the\\nADNI dataset show that RSM can also improve correlation between\\nsubject-specific detections in cortical thickness data and non-imaging markers\\nof Alzheimer's Disease (AD), such as the Mini Mental State Examination Score\\nand Cerebrospinal Fluid amyloid-$\\beta$ levels. Further reliability studies on\\nthe longitudinal ADNI dataset show improvement on detection reliability when\\nRSM is used.\\n    1\n",
            "  The hypothesis that computational models can be reliable enough to be adopted\\nin prognosis and patient care is revolutionizing healthcare. Deep learning, in\\nparticular, has been a game changer in building predictive models, thereby\\nleading to community-wide data curation efforts. However, due to the inherent\\nvariabilities in population characteristics and biological systems, these\\nmodels are often biased to the training datasets. This can be limiting when\\nmodels are deployed in new environments, particularly when there are systematic\\ndomain shifts not known a priori. In this paper, we formalize these challenges\\nby emulating a large class of domain shifts that can occur in clinical\\nsettings, and argue that evaluating the behavior of predictive models in light\\nof those shifts is an effective way of quantifying the reliability of clinical\\nmodels. More specifically, we develop an approach for building challenging\\nscenarios, based on analysis of \\textit{disease landscapes}, and utilize\\nunsupervised domain adaptation to compensate for the domain shifts. Using the\\nopenly available MIMIC-III EHR dataset for phenotyping, we generate a large\\nclass of scenarios and evaluate the ability of deep clinical models in those\\ncases. For the first time, our work sheds light into data regimes where deep\\nclinical models can fail to generalize, due to significant changes in the\\ndisease landscapes between the source and target landscapes. This study\\nemphasizes the need for sophisticated evaluation mechanisms driven by\\nreal-world domain shifts to build effective AI solutions for healthcare.\\n                                                                                                                                                                                                                                                                                                                                      1\n",
            "  In supervised machine learning, an agent is typically trained once and then\\ndeployed. While this works well for static settings, robots often operate in\\nchanging environments and must quickly learn new things from data streams. In\\nthis paradigm, known as streaming learning, a learner is trained online, in a\\nsingle pass, from a data stream that cannot be assumed to be independent and\\nidentically distributed (iid). Streaming learning will cause conventional deep\\nneural networks (DNNs) to fail for two reasons: 1) they need multiple passes\\nthrough the entire dataset; and 2) non-iid data will cause catastrophic\\nforgetting. An old fix to both of these issues is rehearsal. To learn a new\\nexample, rehearsal mixes it with previous examples, and then this mixture is\\nused to update the DNN. Full rehearsal is slow and memory intensive because it\\nstores all previously observed examples, and its effectiveness for preventing\\ncatastrophic forgetting has not been studied in modern DNNs. Here, we describe\\nthe ExStream algorithm for memory efficient rehearsal and compare it to\\nalternatives. We find that full rehearsal can eliminate catastrophic forgetting\\nin a variety of streaming learning settings, with ExStream performing well\\nusing far less memory and computation.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1\n",
            "  Evolutionary game dynamics in structured populations are strongly affected by\\nupdating rules. Previous studies usually focus on imitation-based rules, which\\nrely on payoff information of social peers. Recent behavioral experiments\\nsuggest that whether individuals use such social information for strategy\\nupdating may be crucial to the outcomes of social interactions. This hints at\\nthe importance of considering updating rules without dependence on social\\npeers' payoff information, which, however, is rarely investigated. Here, we\\nstudy aspiration-based self-evaluation rules, with which individuals\\nself-assess the performance of strategies by comparing own payoffs with an\\nimaginary value they aspire, called the aspiration level. We explore the fate\\nof strategies on population structures represented by graphs or networks. Under\\nweak selection, we analytically derive the condition for strategy dominance,\\nwhich is found to coincide with the classical condition of risk-dominance. This\\ncondition holds for all networks and all distributions of aspiration levels,\\nand for individualized ways of self-evaluation. Our condition can be\\nintuitively interpreted: one strategy prevails over the other if the strategy\\nbrings more satisfaction to individuals than the other does. Our work thus\\nsheds light on the intrinsic difference between evolutionary dynamics induced\\nby aspiration-based and imitation-based rules.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1\n",
            "  Millions of users routinely use Google to log in to websites supporting OAuth\\n2.0 or OpenID Connect; the security of OAuth 2.0 and OpenID Connect is\\ntherefore of critical importance. As revealed in previous studies, in practice\\nRPs often implement OAuth 2.0 incorrectly, and so many real-world OAuth 2.0 and\\nOpenID Connect systems are vulnerable to attack. However, users of such flawed\\nsystems are typically unaware of these issues, and so are at risk of attacks\\nwhich could result in unauthorised access to the victim user's account at an\\nRP. In order to address this threat, we have developed OAuthGuard, an OAuth 2.0\\nand OpenID Connect vulnerability scanner and protector, that works with RPs\\nusing Google OAuth 2.0 and OpenID Connect services. It protects user security\\nand privacy even when RPs do not implement OAuth 2.0 or OpenID Connect\\ncorrectly. We used OAuthGuard to survey the 1000 top-ranked websites supporting\\nGoogle sign-in for the possible presence of five OAuth 2.0 or OpenID Connect\\nsecurity and privacy vulnerabilities, of which one has not previously been\\ndescribed in the literature. Of the 137 sites in our study that employ Google\\nSign-in, 69 were found to suffer from at least one serious vulnerability.\\nOAuthGuard was able to protect user security and privacy for 56 of these 69\\nRPs, and for the other 13 was able to warn users that they were using an\\ninsecure implementation.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
            "  We introduce the exit time finite state projection (ETFSP) scheme, a\\ntruncation-based method that yields approximations to the exit distribution and\\noccupation measure associated with the time of exit from a domain (i.e., the\\ntime of first passage to the complement of the domain) of time-homogeneous\\ncontinuous-time Markov chains. We prove that: (i) the computed approximations\\nbound the measures from below; (ii) the total variation distances between the\\napproximations and the measures decrease monotonically as states are added to\\nthe truncation; and (iii) the scheme converges, in the sense that, as the\\ntruncation tends to the entire state space, the total variation distances tend\\nto zero. Furthermore, we give a computable bound on the total variation\\ndistance between the exit distribution and its approximation, and we delineate\\nthe cases in which the bound is sharp. We also revisit the related finite state\\nprojection scheme and give a comprehensive account of its theoretical\\nproperties. We demonstrate the use of the ETFSP scheme by applying it to two\\nbiological examples: the computation of the first passage time associated with\\nthe expression of a gene, and the fixation times of competing species subject\\nto demographic noise.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1\n",
            "  The problem of choice of boundary conditions are discussed for the case of\\nnumerical integration of the shallow water equations on a substantially\\nirregular relief. In modeling of unsteady surface water flows has a dynamic\\nboundary partitioning liquid and dry bottom. The situation is complicated by\\nthe emergence of sub- and supercritical flow regimes for the problems of\\nseasonal floodplain flooding, flash floods, tsunami landfalls. Analysis of the\\nuse of various methods of setting conditions for the physical quantities of\\nliquid when the settlement of the boundary shows the advantages of using the\\nwaterfall type conditions in the presence of strong inhomogeneities landforms.\\nWhen there is a waterfall on the border of the computational domain and\\nheterogeneity of the relief in the vicinity of the boundary portion may occur,\\nwhich is formed by the region of critical flow with the formation of a\\nhydraulic jump, which greatly weakens the effect of the waterfall on the flow\\npattern upstream.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1\n",
            "  We present a new Frank-Wolfe (FW) type algorithm that is applicable to\\nminimization problems with a nonsmooth convex objective. We provide convergence\\nbounds and show that the scheme yields so-called coreset results for various\\nMachine Learning problems including 1-median, Balanced Development, Sparse PCA,\\nGraph Cuts, and the $\\ell_1$-norm-regularized Support Vector Machine (SVM)\\namong others. This means that the algorithm provides approximate solutions to\\nthese problems in time complexity bounds that are not dependent on the size of\\nthe input problem. Our framework, motivated by a growing body of work on\\nsublinear algorithms for various data analysis problems, is entirely\\ndeterministic and makes no use of smoothing or proximal operators. Apart from\\nthese theoretical results, we show experimentally that the algorithm is very\\npractical and in some cases also offers significant computational advantages on\\nlarge problem instances. We provide an open source implementation that can be\\nadapted for other problems that fit the overall structure.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        1\n",
            "  Lately, Wireless Sensor Networks (WSNs) have become an emerging technology\\nand can be utilized in some crucial circumstances like battlegrounds,\\ncommercial applications, habitat observing, buildings, smart homes, traffic\\nsurveillance and other different places. One of the foremost difficulties that\\nWSN faces nowadays is protection from serious attacks. While organizing the\\nsensor nodes in an abandoned environment makes network systems helpless against\\nan assortment of strong assaults, intrinsic memory and power restrictions of\\nsensor nodes make the traditional security arrangements impractical. The\\nsensing knowledge combined with the wireless communication and processing power\\nmakes it lucrative for being abused. The wireless sensor network technology\\nalso obtains a big variety of security intimidations. This paper describes four\\nbasic security threats and many active attacks on WSN with their possible\\ncountermeasures proposed by different research scholars.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1\n",
            "  Recently, optional stopping has been a subject of debate in the Bayesian\\npsychology community. Rouder (2014) argues that optional stopping is no problem\\nfor Bayesians, and even recommends the use of optional stopping in practice, as\\ndo Wagenmakers et al. (2012). This article addresses the question whether\\noptional stopping is problematic for Bayesian methods, and specifies under\\nwhich circumstances and in which sense it is and is not. By slightly varying\\nand extending Rouder's (2014) experiment, we illustrate that, as soon as the\\nparameters of interest are equipped with default or pragmatic priors - which\\nmeans, in most practical applications of Bayes Factor hypothesis testing -\\nresilience to optional stopping can break down. We distinguish between four\\ntypes of default priors, each having their own specific issues with optional\\nstopping, ranging from no-problem-at-all (Type 0 priors) to quite severe (Type\\nII and III priors).\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1\n",
            "Name: ABSTRACT, Length: 20968, dtype: int64\n",
            "0    12374\n",
            "1     8594\n",
            "Name: Computer Science, dtype: int64\n",
            "0    14955\n",
            "1     6013\n",
            "Name: Physics, dtype: int64\n",
            "0    15350\n",
            "1     5618\n",
            "Name: Mathematics, dtype: int64\n",
            "0    15762\n",
            "1     5206\n",
            "Name: Statistics, dtype: int64\n",
            "0    20385\n",
            "1      583\n",
            "Name: Quantitative Biology, dtype: int64\n",
            "0    20723\n",
            "1      245\n",
            "Name: Quantitative Finance, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rldgaM6S7j3",
        "outputId": "f2f49215-acad-496a-f750-7d9dfa403222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20968, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRE-PROCESSING**"
      ],
      "metadata": {
        "id": "UNqdPMheZwE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Article\"] = data[[\"TITLE\", \"ABSTRACT\"]].apply(\"-\".join, axis=1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ggji0znVg57d",
        "outputId": "16838dc8-2394-4665-faff-81cf9a96970d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   TITLE  \\\n",
              "0            Reconstructing Subject-Specific Effect Maps   \n",
              "1                     Rotation Invariance Neural Network   \n",
              "2      Spherical polyharmonics and Poisson kernels fo...   \n",
              "3      A finite element approximation for the stochas...   \n",
              "4      Comparative study of Discrete Wavelet Transfor...   \n",
              "...                                                  ...   \n",
              "20963  Contemporary machine learning: a guide for pra...   \n",
              "20964  Uniform diamond coatings on WC-Co hard alloy c...   \n",
              "20965  Analysing Soccer Games with Clustering and Con...   \n",
              "20966  On the Efficient Simulation of the Left-Tail o...   \n",
              "20967   Why optional stopping is a problem for Bayesians   \n",
              "\n",
              "                                                ABSTRACT  Computer Science  \\\n",
              "0        Predictive models allow subject-specific inf...                 1   \n",
              "1        Rotation invariance and translation invarian...                 1   \n",
              "2        We introduce and develop the notion of spher...                 0   \n",
              "3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "...                                                  ...               ...   \n",
              "20963    Machine learning is finding increasingly bro...                 1   \n",
              "20964    Polycrystalline diamond coatings have been g...                 0   \n",
              "20965    We present a new approach for identifying si...                 1   \n",
              "20966    The sum of Log-normal variates is encountere...                 0   \n",
              "20967    Recently, optional stopping has been a subje...                 0   \n",
              "\n",
              "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0            0            0           0                     0   \n",
              "1            0            0           0                     0   \n",
              "2            0            1           0                     0   \n",
              "3            0            1           0                     0   \n",
              "4            0            0           1                     0   \n",
              "...        ...          ...         ...                   ...   \n",
              "20963        1            0           0                     0   \n",
              "20964        1            0           0                     0   \n",
              "20965        0            0           0                     0   \n",
              "20966        0            1           1                     0   \n",
              "20967        0            1           1                     0   \n",
              "\n",
              "       Quantitative Finance                                            Article  \n",
              "0                         0  Reconstructing Subject-Specific Effect Maps-  ...  \n",
              "1                         0  Rotation Invariance Neural Network-  Rotation ...  \n",
              "2                         0  Spherical polyharmonics and Poisson kernels fo...  \n",
              "3                         0  A finite element approximation for the stochas...  \n",
              "4                         0  Comparative study of Discrete Wavelet Transfor...  \n",
              "...                     ...                                                ...  \n",
              "20963                     0  Contemporary machine learning: a guide for pra...  \n",
              "20964                     0  Uniform diamond coatings on WC-Co hard alloy c...  \n",
              "20965                     0  Analysing Soccer Games with Clustering and Con...  \n",
              "20966                     0  On the Efficient Simulation of the Left-Tail o...  \n",
              "20967                     0  Why optional stopping is a problem for Bayesia...  \n",
              "\n",
              "[20968 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22090aff-e05a-4b58-a023-c25df99c7947\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps-  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Rotation Invariance Neural Network-  Rotation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20963</th>\n",
              "      <td>Contemporary machine learning: a guide for pra...</td>\n",
              "      <td>Machine learning is finding increasingly bro...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Contemporary machine learning: a guide for pra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20964</th>\n",
              "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
              "      <td>Polycrystalline diamond coatings have been g...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
              "      <td>We present a new approach for identifying si...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20966</th>\n",
              "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
              "      <td>The sum of Log-normal variates is encountere...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20967</th>\n",
              "      <td>Why optional stopping is a problem for Bayesians</td>\n",
              "      <td>Recently, optional stopping has been a subje...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Why optional stopping is a problem for Bayesia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20968 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22090aff-e05a-4b58-a023-c25df99c7947')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22090aff-e05a-4b58-a023-c25df99c7947 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22090aff-e05a-4b58-a023-c25df99c7947');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text1(text):\n",
        "    text=text.lower()\n",
        "    text=re.sub('\\[.*?\\]','',text)\n",
        "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
        "    text=re.sub('\\w*\\d\\w*','',text)\n",
        "    return text\n",
        "\n",
        "cleaned1=lambda x:clean_text1(x)"
      ],
      "metadata": {
        "id": "lATcyV2VCsVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article']=pd.DataFrame(data.Article.apply(cleaned1))"
      ],
      "metadata": {
        "id": "FP5giQCbDCD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "\n",
        "#Tokenization of text\n",
        "tokenizer=ToktokTokenizer()\n",
        "#Setting English stopwords\n",
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "kKJc_eFgHupu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()"
      ],
      "metadata": {
        "id": "OuGddXSpHvXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re,string,unicodedata\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)"
      ],
      "metadata": {
        "id": "GFzXmwCoHvT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "soRX8NEEHvSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article']=data['Article'].apply(denoise_text)"
      ],
      "metadata": {
        "id": "NbQvueglHvQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "riE1XKXmHvOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article']=data['Article'].apply(remove_special_characters)"
      ],
      "metadata": {
        "id": "35NbOWY-H85u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming the text\n",
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text"
      ],
      "metadata": {
        "id": "05a-Azz6H822"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article']=data['Article'].apply(simple_stemmer)"
      ],
      "metadata": {
        "id": "iXnS2xUPH80b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "#set stopwords to english\n",
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzc_AMQmH8yQ",
        "outputId": "f4bbbb46-2c94-4d61-a13d-88bdc3aaa626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'as', 'are', 'an', 'that', 'it', 'have', 'has', 'ours', \"haven't\", 'or', 'aren', 'in', \"doesn't\", 'couldn', 'from', 'out', 'o', 'during', 'after', 'other', \"hadn't\", 'isn', 'his', 'mightn', 'he', 'himself', 'was', 'then', \"needn't\", 'd', 'under', 'any', 'against', 'those', 'some', \"didn't\", 'there', 'its', 'is', 'won', 'been', \"hasn't\", 'doesn', 'and', 'when', \"you'll\", 'no', 'this', \"shouldn't\", 'once', 'just', 'each', 'not', 'shouldn', 'their', 'doing', \"you'd\", 'her', 't', 'ain', 'itself', 'until', 'than', 'over', 'down', 'only', 'hasn', 'we', 'ourselves', 'between', 'didn', 'most', 'she', 'theirs', 'be', 'through', 'having', 'more', 'should', 'so', 'own', 'mustn', 'can', \"you're\", 'which', 'ma', 'y', 'they', 'for', 'further', 'with', 'them', \"you've\", \"she's\", 're', 'these', 'haven', \"it's\", 'you', 'hadn', 'what', 'below', 'both', \"shan't\", 'to', 'if', 'm', 'up', 'who', 'yourselves', 'into', 's', 'off', 'yours', 'do', \"isn't\", 'at', 'll', 'very', 'yourself', 'our', 'whom', \"should've\", 'wasn', 'above', 'had', 'nor', 'now', 'i', 'did', 'shan', 'such', 'my', 'don', 'am', \"couldn't\", 'myself', 'herself', 'being', 'me', 'themselves', 'by', \"that'll\", 'same', 'where', 'hers', 'while', 'because', 'why', 'him', 'too', 've', 'of', 'needn', 'wouldn', 'again', 'weren', \"aren't\", 'but', 'a', \"weren't\", 'before', 'here', 'few', 'the', 'about', \"don't\", \"mightn't\", \"wasn't\", 'how', 'all', 'does', 'will', 'on', 'your', 'were', \"won't\", \"wouldn't\", \"mustn't\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article']=data['Article'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "Cv98kQKoH8wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
        "\n",
        "def simple_stemmer(text):\n",
        "    ps = SnowballStemmer(language='english')\n",
        "    return ' '.join([ps.stem(word) for word in tokenizer.tokenize(text)])"
      ],
      "metadata": {
        "id": "l9ngJVIWKzn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Article'][0]"
      ],
      "metadata": {
        "id": "v2WRfDOvvnG6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "88d18acc-9062-4b9d-953e-02dd4a75e3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reconstruct subjectspecif effect map predict model allow subjectspecif infer analyz diseas relat alter neuroimag data given subject data infer made two level global ie identifiy condit presenc subject local ie detect condit effect individu measur extract subject data global infer wide use local infer use form subjectspecif effect map rare use becaus exist model often yield noisi detect compos dispers isol island thi articl propos reconstruct method name rsm improv subjectspecif detect predict model approach particular binari classifi rsm specif aim reduc nois due sampl error associ use finit sampl exampl train classifi propos method wrappertyp algorithm use differ binari classifi diagnost manner ie without inform condit presenc reconstruct pose maximumaposteriori problem prior model whose paramet estim train data classifierspecif fashion experiment evalu perform synthet gener data data alzheim diseas neuroimag initi adni databas result synthet data demonstr use rsm yield higher detect accuraci compar use model directli bootstrap averag analys adni dataset show rsm also improv correl subjectspecif detect cortic thick data nonimag marker alzheim diseas ad mini mental state examin score cerebrospin fluid amyloidbeta level reliabl studi longitudin adni dataset show improv detect reliabl rsm use'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "M0P0YNOqIrya",
        "outputId": "38a0d792-4584-4f1c-c989-1bdad4d52e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   TITLE  \\\n",
              "0            Reconstructing Subject-Specific Effect Maps   \n",
              "1                     Rotation Invariance Neural Network   \n",
              "2      Spherical polyharmonics and Poisson kernels fo...   \n",
              "3      A finite element approximation for the stochas...   \n",
              "4      Comparative study of Discrete Wavelet Transfor...   \n",
              "...                                                  ...   \n",
              "20963  Contemporary machine learning: a guide for pra...   \n",
              "20964  Uniform diamond coatings on WC-Co hard alloy c...   \n",
              "20965  Analysing Soccer Games with Clustering and Con...   \n",
              "20966  On the Efficient Simulation of the Left-Tail o...   \n",
              "20967   Why optional stopping is a problem for Bayesians   \n",
              "\n",
              "                                                ABSTRACT  Computer Science  \\\n",
              "0        Predictive models allow subject-specific inf...                 1   \n",
              "1        Rotation invariance and translation invarian...                 1   \n",
              "2        We introduce and develop the notion of spher...                 0   \n",
              "3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
              "4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
              "...                                                  ...               ...   \n",
              "20963    Machine learning is finding increasingly bro...                 1   \n",
              "20964    Polycrystalline diamond coatings have been g...                 0   \n",
              "20965    We present a new approach for identifying si...                 1   \n",
              "20966    The sum of Log-normal variates is encountere...                 0   \n",
              "20967    Recently, optional stopping has been a subje...                 0   \n",
              "\n",
              "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
              "0            0            0           0                     0   \n",
              "1            0            0           0                     0   \n",
              "2            0            1           0                     0   \n",
              "3            0            1           0                     0   \n",
              "4            0            0           1                     0   \n",
              "...        ...          ...         ...                   ...   \n",
              "20963        1            0           0                     0   \n",
              "20964        1            0           0                     0   \n",
              "20965        0            0           0                     0   \n",
              "20966        0            1           1                     0   \n",
              "20967        0            1           1                     0   \n",
              "\n",
              "       Quantitative Finance                                            Article  \n",
              "0                         0  reconstruct subjectspecif effect map predict m...  \n",
              "1                         0  rotat invari neural network rotat invari trans...  \n",
              "2                         0  spheric polyharmon poisson kernel polyharmon f...  \n",
              "3                         0  finit element approxim stochast maxwelllandaul...  \n",
              "4                         0  compar studi discret wavelet transform wavelet...  \n",
              "...                     ...                                                ...  \n",
              "20963                     0  contemporari machin learn guid practition phys...  \n",
              "20964                     0  uniform diamond coat wcco hard alloy cut inser...  \n",
              "20965                     0  analys soccer game cluster conceptor present n...  \n",
              "20966                     0  effici simul lefttail sum correl lognorm varia...  \n",
              "20967                     0  whi option stop problem bayesian recent option...  \n",
              "\n",
              "[20968 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13abc4bd-1650-48f2-9aff-9c93058358ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Physics</th>\n",
              "      <th>Mathematics</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>Article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
              "      <td>Predictive models allow subject-specific inf...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>reconstruct subjectspecif effect map predict m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rotation Invariance Neural Network</td>\n",
              "      <td>Rotation invariance and translation invarian...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>rotat invari neural network rotat invari trans...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
              "      <td>We introduce and develop the notion of spher...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>spheric polyharmon poisson kernel polyharmon f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A finite element approximation for the stochas...</td>\n",
              "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>finit element approxim stochast maxwelllandaul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
              "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>compar studi discret wavelet transform wavelet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20963</th>\n",
              "      <td>Contemporary machine learning: a guide for pra...</td>\n",
              "      <td>Machine learning is finding increasingly bro...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>contemporari machin learn guid practition phys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20964</th>\n",
              "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
              "      <td>Polycrystalline diamond coatings have been g...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>uniform diamond coat wcco hard alloy cut inser...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
              "      <td>We present a new approach for identifying si...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>analys soccer game cluster conceptor present n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20966</th>\n",
              "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
              "      <td>The sum of Log-normal variates is encountere...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>effici simul lefttail sum correl lognorm varia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20967</th>\n",
              "      <td>Why optional stopping is a problem for Bayesians</td>\n",
              "      <td>Recently, optional stopping has been a subje...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>whi option stop problem bayesian recent option...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20968 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13abc4bd-1650-48f2-9aff-9c93058358ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13abc4bd-1650-48f2-9aff-9c93058358ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13abc4bd-1650-48f2-9aff-9c93058358ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word cloud for positive reviews\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "positive_data = df['Article']\n",
        "positive_data_string = ' '.join(positive_data)\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 2000, width=1200, height=600,background_color=\"white\").generate(positive_data_string)\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud',fontsize = 20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jkxQ5whwbJCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TFIDF Vectors**"
      ],
      "metadata": {
        "id": "6VFY3aylChLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1=data[{'Computer Science','Physics','Mathematics','Statistics','Quantitative Biology','Quantitative Finance','Article'}]\n",
        "data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "TmjebFVNsum4",
        "outputId": "2cd574e1-1313-42a2-aa9f-98c072d89649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Physics                                            Article  \\\n",
              "0            0  reconstruct subjectspecif effect map predict m...   \n",
              "1            0  rotat invari neural network rotat invari trans...   \n",
              "2            0  spheric polyharmon poisson kernel polyharmon f...   \n",
              "3            0  finit element approxim stochast maxwelllandaul...   \n",
              "4            0  compar studi discret wavelet transform wavelet...   \n",
              "...        ...                                                ...   \n",
              "20963        1  contemporari machin learn guid practition phys...   \n",
              "20964        1  uniform diamond coat wcco hard alloy cut inser...   \n",
              "20965        0  analys soccer game cluster conceptor present n...   \n",
              "20966        0  effici simul lefttail sum correl lognorm varia...   \n",
              "20967        0  whi option stop problem bayesian recent option...   \n",
              "\n",
              "       Computer Science  Quantitative Biology  Quantitative Finance  \\\n",
              "0                     1                     0                     0   \n",
              "1                     1                     0                     0   \n",
              "2                     0                     0                     0   \n",
              "3                     0                     0                     0   \n",
              "4                     1                     0                     0   \n",
              "...                 ...                   ...                   ...   \n",
              "20963                 1                     0                     0   \n",
              "20964                 0                     0                     0   \n",
              "20965                 1                     0                     0   \n",
              "20966                 0                     0                     0   \n",
              "20967                 0                     0                     0   \n",
              "\n",
              "       Statistics  Mathematics  \n",
              "0               0            0  \n",
              "1               0            0  \n",
              "2               0            1  \n",
              "3               0            1  \n",
              "4               1            0  \n",
              "...           ...          ...  \n",
              "20963           0            0  \n",
              "20964           0            0  \n",
              "20965           0            0  \n",
              "20966           1            1  \n",
              "20967           1            1  \n",
              "\n",
              "[20968 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9ecd7de-7da0-4895-9abd-f37870fc612f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Physics</th>\n",
              "      <th>Article</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Mathematics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>reconstruct subjectspecif effect map predict m...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>rotat invari neural network rotat invari trans...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>spheric polyharmon poisson kernel polyharmon f...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>finit element approxim stochast maxwelllandaul...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>compar studi discret wavelet transform wavelet...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20963</th>\n",
              "      <td>1</td>\n",
              "      <td>contemporari machin learn guid practition phys...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20964</th>\n",
              "      <td>1</td>\n",
              "      <td>uniform diamond coat wcco hard alloy cut inser...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>0</td>\n",
              "      <td>analys soccer game cluster conceptor present n...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20966</th>\n",
              "      <td>0</td>\n",
              "      <td>effici simul lefttail sum correl lognorm varia...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20967</th>\n",
              "      <td>0</td>\n",
              "      <td>whi option stop problem bayesian recent option...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20968 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9ecd7de-7da0-4895-9abd-f37870fc612f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9ecd7de-7da0-4895-9abd-f37870fc612f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9ecd7de-7da0-4895-9abd-f37870fc612f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nWith TFIDFVectorizer\")\n",
        "vectorizer = TfidfVectorizer(max_features=10)\n",
        "X = vectorizer.fit_transform(data1.Article)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())\n",
        "print(\"\\n\")\n",
        "#print(cosine_similarity(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-oRf6JAHQ1-",
        "outputId": "6c3d0341-a789-4263-c73b-41da0792a93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "With TFIDFVectorizer\n",
            "['data' 'gener' 'method' 'model' 'network' 'result' 'show' 'system' 'thi'\n",
            " 'use']\n",
            "[[0.72425956 0.08379927 0.17205836 ... 0.         0.05137542 0.5105419 ]\n",
            " [0.         0.         0.         ... 0.         0.31188669 0.19371038]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.17202716 0.         0.         ... 0.         0.         0.60632318]\n",
            " [0.         0.         0.44003749 ... 0.47959423 0.         0.        ]\n",
            " [0.         0.         0.72415862 ... 0.         0.43245733 0.53719173]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nWith TFIDFVectorizer and removing stop words\")\n",
        "vectorizer = TfidfVectorizer(stop_words=nlp.Defaults.stop_words,max_features=10)\n",
        "X = vectorizer.fit_transform(data1.Article)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())\n",
        "print(\"\\n\")\n",
        "#print(cosine_similarity(X))"
      ],
      "metadata": {
        "id": "3uJlXWeCHWSB",
        "outputId": "242d3bee-94f4-45e1-e6ca-c53e79ba6d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "With TFIDFVectorizer and removing stop words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data' 'gener' 'method' 'model' 'network' 'problem' 'result' 'system'\n",
            " 'thi' 'use']\n",
            "[[0.72976199 0.08443592 0.17336555 ... 0.         0.05176573 0.51442065]\n",
            " [0.         0.         0.         ... 0.         0.31188669 0.19371038]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.17202716 0.         0.         ... 0.         0.         0.60632318]\n",
            " [0.         0.         0.39862582 ... 0.43445989 0.         0.        ]\n",
            " [0.         0.         0.39460872 ... 0.         0.23565477 0.29272667]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "O3x-1NWdz_C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= data1['Article']\n",
        "y=data1.drop(\"Article\", axis=1)\n",
        "X.head"
      ],
      "metadata": {
        "id": "uZkF9BntunJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ceaf10-54cc-4dd3-e6de-39874a501801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of 0        reconstruct subjectspecif effect map predict m...\n",
              "1        rotat invari neural network rotat invari trans...\n",
              "2        spheric polyharmon poisson kernel polyharmon f...\n",
              "3        finit element approxim stochast maxwelllandaul...\n",
              "4        compar studi discret wavelet transform wavelet...\n",
              "                               ...                        \n",
              "20963    contemporari machin learn guid practition phys...\n",
              "20964    uniform diamond coat wcco hard alloy cut inser...\n",
              "20965    analys soccer game cluster conceptor present n...\n",
              "20966    effici simul lefttail sum correl lognorm varia...\n",
              "20967    whi option stop problem bayesian recent option...\n",
              "Name: Article, Length: 20968, dtype: object>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Ty1-0DrzHRF6",
        "outputId": "daa47213-d575-44ce-edde-c07845fa1472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Physics  Computer Science  Quantitative Biology  Quantitative Finance  \\\n",
              "0            0                 1                     0                     0   \n",
              "1            0                 1                     0                     0   \n",
              "2            0                 0                     0                     0   \n",
              "3            0                 0                     0                     0   \n",
              "4            0                 1                     0                     0   \n",
              "...        ...               ...                   ...                   ...   \n",
              "20963        1                 1                     0                     0   \n",
              "20964        1                 0                     0                     0   \n",
              "20965        0                 1                     0                     0   \n",
              "20966        0                 0                     0                     0   \n",
              "20967        0                 0                     0                     0   \n",
              "\n",
              "       Statistics  Mathematics  \n",
              "0               0            0  \n",
              "1               0            0  \n",
              "2               0            1  \n",
              "3               0            1  \n",
              "4               1            0  \n",
              "...           ...          ...  \n",
              "20963           0            0  \n",
              "20964           0            0  \n",
              "20965           0            0  \n",
              "20966           1            1  \n",
              "20967           1            1  \n",
              "\n",
              "[20968 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eacdc6a9-3941-40be-ad88-2955dba12019\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Physics</th>\n",
              "      <th>Computer Science</th>\n",
              "      <th>Quantitative Biology</th>\n",
              "      <th>Quantitative Finance</th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Mathematics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20963</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20964</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20965</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20966</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20967</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20968 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eacdc6a9-3941-40be-ad88-2955dba12019')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eacdc6a9-3941-40be-ad88-2955dba12019 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eacdc6a9-3941-40be-ad88-2955dba12019');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=0)"
      ],
      "metadata": {
        "id": "XjcUvHkCsZ9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "B1s1CTwwsZ7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "lg = sklearn.linear_model.LogisticRegression()"
      ],
      "metadata": {
        "id": "mtA1PYv0sZ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "model =  MultiOutputClassifier(lg)"
      ],
      "metadata": {
        "id": "q11SmHl1sZ3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "tdFynfudvOeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bc8121-50cd-4a99-f34d-70fa7175977f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputClassifier(estimator=LogisticRegression())"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy on test data: {:.1f}%'.format(accuracy_score(y_test, model.predict(X_test))*100))"
      ],
      "metadata": {
        "id": "bDwUKLtOvOay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc45b6dc-9ad2-4c3a-fbb1-e60c2aafc739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 63.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WORD2VEC**\n"
      ],
      "metadata": {
        "id": "oT4lNnxuMXC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "YtNzCw3OvOYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [review.split() for review in data['Article']]\n",
        "model = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)\n",
        "model.save('word2vec.model')"
      ],
      "metadata": {
        "id": "NYfdzDhJsKDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each word to vector and represent the sentence in vector form using the word embeddings\n",
        "def sentence_vector(sentence,model):\n",
        "    words = sentence.split()\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv.vocab]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros((100,))\n",
        "    return np.mean(word_vectors, axis=0)"
      ],
      "metadata": {
        "id": "jJxjUFSVHfrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##LOGISTIC REGRESSION\n",
        "\n"
      ],
      "metadata": {
        "id": "4vsWcIbO4sYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert each sentence in the dataset to a vector using the Word2Vec model\n",
        "word2vec_train = np.array([sentence_vector(sentence, model) for sentence in data1['Article']])\n",
        "word2vec_test = np.array(y)"
      ],
      "metadata": {
        "id": "BTzSjlY2H8fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_train, word2vec_test, test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "Mic9LFitH8bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg = sklearn.linear_model.LogisticRegression()"
      ],
      "metadata": {
        "id": "Zd3KHURAH8Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 =  MultiOutputClassifier(lg)"
      ],
      "metadata": {
        "id": "aoNfAM-qH8OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbDuWNSISIuo",
        "outputId": "e642cedd-6b51-4435-8680-40b612d91b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputClassifier(estimator=LogisticRegression())"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy on test data: {:.1f}%'.format(accuracy_score(y_test, model1.predict(X_test))*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lpx0LvrBSJsO",
        "outputId": "b00d40e0-bf24-4592-96a1-d819a3c424d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 63.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMBINING TFIDF AND WORD2VEC**"
      ],
      "metadata": {
        "id": "OMrMFGc3tcWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_vectors(doc):\n",
        "    tfidf_vec = vectorizer.transform([doc])\n",
        "    w2v_vec = sentence_vector(doc, model)\n",
        "    combined_vec = np.concatenate([np.squeeze(tfidf_vec.toarray()), w2v_vec])\n",
        "    return combined_vec"
      ],
      "metadata": {
        "id": "CSPvbj3BTL-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "H7mdM9WAa1WC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_train = np.array([combine_vectors(doc) for doc in data['Article']])\n",
        "combined_test = np.array(y)"
      ],
      "metadata": {
        "id": "cM3tUZACTL7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(combined_train, combined_test, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "V2dBnBQmTL5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lg2 = sklearn.linear_model.LogisticRegression()"
      ],
      "metadata": {
        "id": "2FFcmejqTL2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 =  MultiOutputClassifier(lg2)"
      ],
      "metadata": {
        "id": "e7f4RkezTLwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uilu53scuT9k",
        "outputId": "5d24f6fd-98da-40b4-818f-a0c972120803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputClassifier(estimator=LogisticRegression())"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy on test data: {:.1f}%'.format(accuracy_score(y_test, model2.predict(X_test))*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdmxW3S6ukqU",
        "outputId": "a21b81a8-3ec8-46b5-a98a-7894f2f7c4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data: 65.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgX1mDsRsWQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}